{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   uid type  Interested  Distressed  Upset  Strong  Guilty  Scared  Hostile   \\\n",
       " 0  u00  pre           5           4      3       4     3.0       5         5   \n",
       " 1  u01  pre           4           2      2       2     5.0       1         1   \n",
       " 2  u02  pre           4           1      1       2     2.0       2         1   \n",
       " 3  u03  pre           4           2      2       4     5.0       5         5   \n",
       " 4  u04  pre           4           2      1       3     3.0       1         1   \n",
       " \n",
       "    Enthusiastic  Proud  Irritable  Alert  Inspired  Nervous  Determined   \\\n",
       " 0             3      3          3      4       4.0      NaN            4   \n",
       " 1             3      3          2      4       3.0      3.0            4   \n",
       " 2             3      2          2      3       2.0      2.0            2   \n",
       " 3             3      1          1      5       3.0      1.0            3   \n",
       " 4             3      3          2      3       1.0      2.0            3   \n",
       " \n",
       "    Attentive  Jittery  Active   Afraid   \n",
       " 0        3.0      2.0        2        5  \n",
       " 1        3.0      2.0        4        1  \n",
       " 2        3.0      3.0        2        1  \n",
       " 3        3.0      5.0        4        1  \n",
       " 4        3.0      1.0        4        1  ,\n",
       " Index(['uid', 'type', 'Interested', 'Distressed', 'Upset', 'Strong', 'Guilty',\n",
       "        'Scared', 'Hostile ', 'Enthusiastic', 'Proud', 'Irritable', 'Alert',\n",
       "        'Inspired', 'Nervous', 'Determined ', 'Attentive', 'Jittery', 'Active ',\n",
       "        'Afraid '],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "file_path = './survey/panas.csv'\n",
    "panas_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe and its columns to understand its structure\n",
    "panas_data.head(), panas_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Interested: ['5' '4' '3' '2' '1']\n",
      "Unique values in Distressed: ['4' '2' '1' '3' '5']\n",
      "Unique values in Upset: ['3' '2' '1' '5' '4']\n",
      "NaN counts after mapping:\n",
      "uid             0\n",
      "type            0\n",
      "Interested      0\n",
      "Distressed      0\n",
      "Upset           0\n",
      "Strong          0\n",
      "Guilty          1\n",
      "Scared          0\n",
      "Hostile         0\n",
      "Enthusiastic    0\n",
      "Proud           0\n",
      "Irritable       0\n",
      "Alert           0\n",
      "Inspired        1\n",
      "Nervous         1\n",
      "Determined      0\n",
      "Attentive       1\n",
      "Jittery         1\n",
      "Active          0\n",
      "Afraid          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in panas_data.columns[2:5]:  # Check first three survey columns\n",
    "    print(f\"Unique values in {column}: {panas_data[column].astype(str).str.strip().str.title().unique()}\")\n",
    "    \n",
    "print(\"NaN counts after mapping:\")\n",
    "print(panas_data.isna().sum())\n",
    "\n",
    "panas_data.fillna(3, inplace=True)  # Assuming 3 is the neutral score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique 'type' values before adjustment: ['pre' 'post']\n",
      "Unique 'uid' values check (sample): 56    u15\n",
      "8     u09\n",
      "78    u49\n",
      "16    u18\n",
      "71    u36\n",
      "Name: uid, dtype: object\n",
      "Number of participants in Pre only: 46\n",
      "Number of participants in Post only: 39\n",
      "Number of common participants: 38\n",
      "Final Pre data counts (non-NaN):\n",
      "uid             38\n",
      "type            38\n",
      "Interested      38\n",
      "Distressed      38\n",
      "Upset           38\n",
      "Strong          38\n",
      "Guilty          38\n",
      "Scared          38\n",
      "Hostile         38\n",
      "Enthusiastic    38\n",
      "Proud           38\n",
      "Irritable       38\n",
      "Alert           38\n",
      "Inspired        38\n",
      "Nervous         38\n",
      "Determined      38\n",
      "Attentive       38\n",
      "Jittery         38\n",
      "Active          38\n",
      "Afraid          38\n",
      "dtype: int64\n",
      "\n",
      "Final Post data counts (non-NaN):\n",
      "uid             38\n",
      "type            38\n",
      "Interested      38\n",
      "Distressed      38\n",
      "Upset           38\n",
      "Strong          38\n",
      "Guilty          38\n",
      "Scared          38\n",
      "Hostile         38\n",
      "Enthusiastic    38\n",
      "Proud           38\n",
      "Irritable       38\n",
      "Alert           38\n",
      "Inspired        38\n",
      "Nervous         38\n",
      "Determined      38\n",
      "Attentive       38\n",
      "Jittery         38\n",
      "Active          38\n",
      "Afraid          38\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique 'type' values before adjustment:\", panas_data['type'].unique())\n",
    "\n",
    "# Normalize 'type' field for consistency\n",
    "panas_data['type'] = panas_data['type'].str.strip().str.title()\n",
    "\n",
    "# Verify 'uid' consistency and format\n",
    "print(\"Unique 'uid' values check (sample):\", panas_data['uid'].sample(5))\n",
    "\n",
    "# Identify participants who have both Pre and Post data\n",
    "pre_participants = set(panas_data[panas_data['type'] == 'Pre']['uid'])\n",
    "post_participants = set(panas_data[panas_data['type'] == 'Post']['uid'])\n",
    "common_participants = pre_participants & post_participants\n",
    "\n",
    "print(f\"Number of participants in Pre only: {len(pre_participants)}\")\n",
    "print(f\"Number of participants in Post only: {len(post_participants)}\")\n",
    "print(f\"Number of common participants: {len(common_participants)}\")\n",
    "\n",
    "# Filter datasets to only include common participants\n",
    "pre_data = panas_data[(panas_data['type'] == 'Pre') & (panas_data['uid'].isin(common_participants))]\n",
    "post_data = panas_data[(panas_data['type'] == 'Post') & (panas_data['uid'].isin(common_participants))]\n",
    "\n",
    "# Save the filtered data\n",
    "pre_data.to_csv('./data/Panas/Panas_Pre.csv', index=False)\n",
    "post_data.to_csv('./data/Panas/Panas_Post.csv', index=False)\n",
    "\n",
    "# Check final data counts\n",
    "print(\"Final Pre data counts (non-NaN):\")\n",
    "print(pre_data.count())\n",
    "print(\"\\nFinal Post data counts (non-NaN):\")\n",
    "print(post_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/7_vy00qd22s8smf_25g57dwm0000gn/T/ipykernel_99487/69265514.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre_data['Positive_Total'] = pre_data[positive_columns_pre].sum(axis=1)\n",
      "/var/folders/gb/7_vy00qd22s8smf_25g57dwm0000gn/T/ipykernel_99487/69265514.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre_data['Negative_Total'] = pre_data[negative_columns_pre].sum(axis=1)\n",
      "/var/folders/gb/7_vy00qd22s8smf_25g57dwm0000gn/T/ipykernel_99487/69265514.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  post_data['Positive_Total'] = post_data[positive_columns_post].sum(axis=1)\n",
      "/var/folders/gb/7_vy00qd22s8smf_25g57dwm0000gn/T/ipykernel_99487/69265514.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  post_data['Negative_Total'] = post_data[negative_columns_post].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Adjust the indices to start from index 2 in the dataframe\n",
    "positive_indices = [2, 5, 9, 10, 12, 13, 15, 16, 18]  # Adjusted for 0-based indexing and shifted right by 2\n",
    "negative_indices = [3, 4, 6, 7, 8, 11, 14, 17, 19]  # Adjusted for 0-based indexing and shifted right by 2\n",
    "\n",
    "# Extract column names for the positive and negative affects\n",
    "positive_columns_pre = pre_data.columns[positive_indices]\n",
    "negative_columns_pre = pre_data.columns[negative_indices]\n",
    "\n",
    "positive_columns_post = post_data.columns[positive_indices]\n",
    "negative_columns_post = post_data.columns[negative_indices]\n",
    "\n",
    "# Recalculate total scores for positive and negative affect for each user\n",
    "pre_data['Positive_Total'] = pre_data[positive_columns_pre].sum(axis=1)\n",
    "pre_data['Negative_Total'] = pre_data[negative_columns_pre].sum(axis=1)\n",
    "\n",
    "post_data['Positive_Total'] = post_data[positive_columns_post].sum(axis=1)\n",
    "post_data['Negative_Total'] = post_data[negative_columns_post].sum(axis=1)\n",
    "\n",
    "pre_data.to_csv('./data/Panas/Panas_Pre.csv', index=False)\n",
    "post_data.to_csv('./data/Panas/Panas_Post.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre and Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre data normality test: statistic=0.9637963175773621, p-value=0.2516540288925171\n",
      "Post data normality test: statistic=0.9762231111526489, p-value=0.5842457413673401\n",
      "T-statistic: -0.05351634106993908, p-value: 0.957608425249791\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Load the pre and post survey data from separate CSV files\n",
    "pre_data = pd.read_csv('./data/Panas/Panas_Pre.csv')\n",
    "post_data = pd.read_csv('./data/Panas/Panas_Post.csv')\n",
    "\n",
    "# Merge the pre and post survey data on the 'uid' column\n",
    "merged_data = pd.merge(pre_data, post_data, on='uid', suffixes=('_pre', '_post'))\n",
    "\n",
    "stat_pre, p_pre = stats.shapiro(merged_data['Positive_Total_pre'])\n",
    "stat_post, p_post = stats.shapiro(merged_data['Positive_Total_post'])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Pre data normality test: statistic={stat_pre}, p-value={p_pre}\")\n",
    "print(f\"Post data normality test: statistic={stat_post}, p-value={p_post}\")\n",
    "\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_stat, p_value = stats.ttest_rel(merged_data['Positive_Total_post'], merged_data['Positive_Total_pre'])\n",
    "\n",
    "print(f\"T-statistic: {t_stat}, p-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
